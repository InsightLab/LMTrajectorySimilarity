{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000  15000  16000  17000  18000  19000  20000  21000\t22000  23000\r\n"
     ]
    }
   ],
   "source": [
    "!ls '../data/saved_models/SBERT/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Carregando o SBERT:\n",
    "model = SentenceTransformer('../data/saved_models/SBERT/22000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine-Similarity: 0.9844686985015869\n"
     ]
    }
   ],
   "source": [
    "# Now you can use the loaded model to encode sentences\n",
    "sentence1 = '17321 10721 17321 10721 11693 10721 11693'\n",
    "emb1 = model.encode(sentence1)\n",
    "sentence2 = '17321 10721 17321 10721 11693 10721'\n",
    "emb2 = model.encode(sentence2)\n",
    "\n",
    "cos_sim = util.cos_sim(emb1, emb2)\n",
    "print(\"Cosine-Similarity:\", cos_sim.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando as trajs de teste:\n",
    "trajs_teste = []\n",
    "with open('../data/exp1-trj.t') as f:\n",
    "    for line in f:\n",
    "        traj_list = line.strip().split()\n",
    "        trajs_teste.append(traj_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1691490709555,
     "user": {
      "displayName": "Wilken Charles",
      "userId": "08238201343018523362"
     },
     "user_tz": 180
    },
    "id": "bpT-8Hcxz2G2",
    "outputId": "6b5a5c92-8cb1-422d-ac28-34b910839eb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de trajetórias de teste: 50500\n"
     ]
    }
   ],
   "source": [
    "print(\"Quantidade de trajetórias de teste:\", len(trajs_teste))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['3']\n"
     ]
    }
   ],
   "source": [
    "print(trajs_teste[2]) # query par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['740', '9617', '5782', '4912', '788', '7087', '680', '306', '9347', '1118', '5399', '2583', '37', '6469', '118', '5766', '8162', '11397', '1159', '310', '4493']\n"
     ]
    }
   ],
   "source": [
    "print(trajs_teste[1002]) # \"alvo\" da query par, ou seja, a query ímpar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As trajs de testes estão uma lista de listas, onda cada lista insterna contém uma traj tokenizada:\n",
    "# [['3176', '1346', '1301', '3303'], ..., ['508', '465', '1641']] \n",
    "# Como SBERT codifica cada sentença (e.x: '508', '465', '1641') para embedding, usamos a função abaixo \n",
    "# que recebe uma traj tokenizada e a retorna em formato de sentence string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traj2str(traj):\n",
    "    \"\"\"\n",
    "    input: ['75476610', '75466888', '75476610', '754960']\n",
    "      out: '75476610 75466888 75476610 754960'\n",
    "    \"\"\"\n",
    "    string_traj = ' '.join(traj)\n",
    "    return string_traj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'55 3 104 244'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista = ['55', '3', '104', '244']\n",
    "traj2str(lista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings_for_all_sentences(trajs):\n",
    "    \"\"\"\n",
    "    Input: list of list de trajs. Trajetória formada por ids cels.\n",
    "    (e.x. trajs = [['30405995', '30413746', '30421497'], ['30429247', '30429248', '30436998']])\n",
    "    Outpu: embedding de cada trajetória/sentença completa (traj) fornecido diretamente pelo SBERT\n",
    "    \"\"\"\n",
    "\n",
    "    t_emb = model.encode(traj2str(trajs[0]))\n",
    "    list_embs = np.empty([len(trajs), t_emb.shape[0]], dtype=np.float32)\n",
    "\n",
    "    i = 0\n",
    "    total = len(trajs)\n",
    "    for traj in trajs:\n",
    "        list_embs[i] = model.encode(traj2str(traj))\n",
    "        i += 1\n",
    "      \n",
    "        # Calcula a porcentagem concluída\n",
    "        percent_done = (i / total) * 100\n",
    "        # Exibe a porcentagem concluída\n",
    "        print(f\"Progresso: {percent_done:.2f}% concluído\", end=\"\\r\")  # A opção `end=\"\\r\"` permite que a impressão seja substituída na mesma linha\n",
    "\n",
    "    return list_embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "fkv5lR35nvNq"
   },
   "outputs": [],
   "source": [
    "# Segmentando: query (trajs pares) e dbsearch (querys ímpar + 99000 outras ímpares)\n",
    "query = trajs_teste[:500] # trajs query (pares)\n",
    "dbsearch = trajs_teste[500:50500] # dbsearch trajs (as 1000 primeiras são as query ímpar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "50000\n"
     ]
    }
   ],
   "source": [
    "print(len(query))\n",
    "print(len(dbsearch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "ngZQea7Q-sIL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.06 s, sys: 16.5 ms, total: 3.08 s\n",
      "Wall time: 3.07 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "query = get_embeddings_for_all_sentences(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 54s, sys: 400 ms, total: 4min 55s\n",
      "Wall time: 4min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dbsearch = get_embeddings_for_all_sentences(dbsearch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "_bR983alydN4"
   },
   "outputs": [],
   "source": [
    "def rank(t_query, i, db_search): \n",
    "    dists = cosine_distances(t_query.reshape(1, -1), db_search) # pega todas as distâncias de Dq[i] as trajs do db_search (D_qUD_p)\n",
    "    dists = dists.flatten()\n",
    "    order = dists.argsort() # pega a ordem\n",
    "    ranks = order.argsort() # pega o rank\n",
    "\n",
    "    return ranks[i] + 1 # retorna o ranking de ta' no dbsearch | soma +1 pq o argsort rankea a partir de 0 (zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "KYObsBJvjxeT"
   },
   "outputs": [],
   "source": [
    "def acc(ranks):\n",
    "    count = 0\n",
    "    for i in range(len(ranks)):\n",
    "        if ranks[i] == 1:\n",
    "            count += 1\n",
    "\n",
    "    return round(count/len(ranks), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mr(ranks):\n",
    "    return (sum(ranks)/len(ranks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mrr(ranks):\n",
    "    count = 0\n",
    "    for i in range(len(ranks)):\n",
    "        count += 1/ranks[i]\n",
    "\n",
    "    return round(count/len(ranks), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intervalo de Confiança do Ranks\n",
    "def cip_r(ranks):\n",
    "    data = []\n",
    "    for i in range(len(ranks)):\n",
    "        data.append(ranks[i]) # Add os Ranks\n",
    "    \n",
    "    #create 95% confidence interval for population mean weight\n",
    "    ic = st.t.interval(alpha=0.95, df=len(data)-1, loc=np.mean(data), scale=st.sem(data))\n",
    "    \n",
    "    return tuple(round(valor, 3) for valor in ic) # arredonda pra 3 casas decimais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intervalo de Confiança dos Reciprocal Ranks\n",
    "def cip_rr(ranks):\n",
    "    data = []\n",
    "    for i in range(len(ranks)):\n",
    "        data.append(1/ranks[i]) # Add os RRs...\n",
    "    \n",
    "    #create 95% confidence interval for population mean weight\n",
    "    ic = st.t.interval(alpha=0.95, df=len(data)-1, loc=np.mean(data), scale=st.sem(data))\n",
    "    \n",
    "    return tuple(round(valor, 3) for valor in ic) # arredonda pra 3 casas decimais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean rank: 172.488(132.84, 212.136), Acc: 0.62, MRR: 0.68(0.645, 0.72) with dbsearch size: 10000\n",
      "Mean rank: 259.284(199.697, 318.871), Acc: 0.58, MRR: 0.65(0.61, 0.686) with dbsearch size: 20000\n",
      "Mean rank: 415.674(319.517, 511.831), Acc: 0.56, MRR: 0.63(0.591, 0.668) with dbsearch size: 30000\n",
      "Mean rank: 544.986(418.795, 671.177), Acc: 0.55, MRR: 0.62(0.579, 0.657) with dbsearch size: 40000\n",
      "Mean rank: 726.276(558.32, 894.232), Acc: 0.55, MRR: 0.61(0.574, 0.652) with dbsearch size: 50000\n",
      "CPU times: user 10min 11s, sys: 18min 46s, total: 28min 57s\n",
      "Wall time: 7min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# checkpoint-22000 (best_model)\n",
    "dbsizes = [10000, 20000, 30000, 40000, 50000]\n",
    "for dbsize in dbsizes:\n",
    "    ranks = []\n",
    "    search = dbsearch[:dbsize]\n",
    "    for i in range(len(query)):\n",
    "        ranks.append(rank(query[i], i, search)) # rank das ta' no dbsearch!\n",
    "    print('Mean rank: {}{}, Acc: {}, MRR: {}{} with dbsearch size: {}'.format(mr(ranks), cip_r(ranks), acc(ranks), mrr(ranks), cip_rr(ranks), dbsize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOqaLWH44Jej+GzpQB7LCw5",
   "collapsed_sections": [
    "3CNDIKIh5PxT"
   ],
   "machine_shape": "hm",
   "mount_file_id": "180jxnrEfenoBKq14C11iOaIFCq1ZhZJv",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
