{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000  10000  2000  3000  4000  5000  6000  7000  8000  9000\r\n"
     ]
    }
   ],
   "source": [
    "!ls '../data/saved_models/SBERT/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Carregando o SBERT:\n",
    "model = SentenceTransformer('../data/saved_models/SBERT/9000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine-Similarity: 0.9790315628051758\n"
     ]
    }
   ],
   "source": [
    "# Now you can use the loaded model to encode sentences\n",
    "sentence1 = '506 112 144 148 250 258 384'\n",
    "emb1 = model.encode(sentence1)\n",
    "sentence2 = '506 112 144 148 258 384'\n",
    "emb2 = model.encode(sentence2)\n",
    "\n",
    "cos_sim = util.cos_sim(emb1, emb2)\n",
    "print(\"Cosine-Similarity:\", cos_sim.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando as trajs de teste:\n",
    "trajs_teste = []\n",
    "with open('../data/exp1-trj.t') as f:\n",
    "    for line in f:\n",
    "        traj_list = line.strip().split()\n",
    "        trajs_teste.append(traj_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1691490709555,
     "user": {
      "displayName": "Wilken Charles",
      "userId": "08238201343018523362"
     },
     "user_tz": 180
    },
    "id": "bpT-8Hcxz2G2",
    "outputId": "6b5a5c92-8cb1-422d-ac28-34b910839eb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de trajetórias de teste: 101000\n"
     ]
    }
   ],
   "source": [
    "print(\"Quantidade de trajetórias de teste:\", len(trajs_teste))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['51', '2263', '345', '53', '120', '405', '803', '585', '692', '1566', '533', '1728', '1880', '739', '544', '226', '8']\n"
     ]
    }
   ],
   "source": [
    "print(trajs_teste[2]) # query par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['51', '430', '345', '120', '856', '131', '673', '585', '233', '2200', '533', '361', '1299', '1215', '66', '588', '7', '8']\n"
     ]
    }
   ],
   "source": [
    "print(trajs_teste[1002]) # \"alvo\" da query par, ou seja, a query ímpar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As trajs de testes estão uma lista de listas, onda cada lista insterna contém uma traj tokenizada:\n",
    "# [['3176', '1346', '1301', '3303'], ..., ['508', '465', '1641']] \n",
    "# Como SBERT codifica cada sentença (e.x: '508', '465', '1641') para embedding, usamos a função abaixo \n",
    "# que recebe uma traj tokenizada e a retorna em formato de sentence string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traj2str(traj):\n",
    "    \"\"\"\n",
    "    input: ['75476610', '75466888', '75476610', '754960']\n",
    "      out: '75476610 75466888 75476610 754960'\n",
    "    \"\"\"\n",
    "    string_traj = ' '.join(traj)\n",
    "    return string_traj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'55 3 104 244'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista = ['55', '3', '104', '244']\n",
    "traj2str(lista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings_for_all_sentences(trajs):\n",
    "    \"\"\"\n",
    "    Input: list of list de trajs. Trajetória formada por ids cels.\n",
    "    (e.x. trajs = [['30405995', '30413746', '30421497'], ['30429247', '30429248', '30436998']])\n",
    "    Outpu: embedding de cada trajetória/sentença completa (traj) fornecido diretamente pelo SBERT\n",
    "    \"\"\"\n",
    "\n",
    "    t_emb = model.encode(traj2str(trajs[0]))\n",
    "    list_embs = np.empty([len(trajs), t_emb.shape[0]], dtype=np.float32)\n",
    "\n",
    "    i = 0\n",
    "    total = len(trajs)\n",
    "    for traj in trajs:\n",
    "        list_embs[i] = model.encode(traj2str(traj))\n",
    "        i += 1\n",
    "      \n",
    "        # Calcula a porcentagem concluída\n",
    "        percent_done = (i / total) * 100\n",
    "        # Exibe a porcentagem concluída\n",
    "        print(f\"Progresso: {percent_done:.2f}% concluído\", end=\"\\r\")  # A opção `end=\"\\r\"` permite que a impressão seja substituída na mesma linha\n",
    "\n",
    "    return list_embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "fkv5lR35nvNq"
   },
   "outputs": [],
   "source": [
    "# Segmentando: query (trajs pares) e dbsearch (querys ímpar + 99000 outras ímpares)\n",
    "query = trajs_teste[:1000] # trajs query (pares)\n",
    "dbsearch = trajs_teste[1000:101000] # dbsearch trajs (as 1000 primeiras são as query ímpar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "100000\n"
     ]
    }
   ],
   "source": [
    "print(len(query))\n",
    "print(len(dbsearch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "ngZQea7Q-sIL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.14 s, sys: 23 ms, total: 4.16 s\n",
      "Wall time: 4.16 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "query = get_embeddings_for_all_sentences(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7min 31s, sys: 263 ms, total: 7min 32s\n",
      "Wall time: 7min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dbsearch = get_embeddings_for_all_sentences(dbsearch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "_bR983alydN4"
   },
   "outputs": [],
   "source": [
    "def rank(t_query, i, db_search): \n",
    "    dists = cosine_distances(t_query.reshape(1, -1), db_search) # pega todas as distâncias de Dq[i] as trajs do db_search (D_qUD_p)\n",
    "    dists = dists.flatten()\n",
    "    order = dists.argsort() # pega a ordem\n",
    "    ranks = order.argsort() # pega o rank\n",
    "\n",
    "    return ranks[i] + 1 # retorna o ranking de ta' no dbsearch | soma +1 pq o argsort rankea a partir de 0 (zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "KYObsBJvjxeT"
   },
   "outputs": [],
   "source": [
    "def acc(ranks):\n",
    "    count = 0\n",
    "    for i in range(len(ranks)):\n",
    "        if ranks[i] == 1:\n",
    "            count += 1\n",
    "\n",
    "    return round(count/len(ranks), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mr(ranks):\n",
    "    return (sum(ranks)/len(ranks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mrr(ranks):\n",
    "    count = 0\n",
    "    for i in range(len(ranks)):\n",
    "        count += 1/ranks[i]\n",
    "\n",
    "    return round(count/len(ranks), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intervalo de Confiança do Ranks\n",
    "def cip_r(ranks):\n",
    "    data = []\n",
    "    for i in range(len(ranks)):\n",
    "        data.append(ranks[i]) # Add os Ranks\n",
    "    \n",
    "    #create 95% confidence interval for population mean weight\n",
    "    ic = st.t.interval(alpha=0.95, df=len(data)-1, loc=np.mean(data), scale=st.sem(data))\n",
    "    \n",
    "    return tuple(round(valor, 3) for valor in ic) # arredonda pra 3 casas decimais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intervalo de Confiança dos Reciprocal Ranks\n",
    "def cip_rr(ranks):\n",
    "    data = []\n",
    "    for i in range(len(ranks)):\n",
    "        data.append(1/ranks[i]) # Add os RRs...\n",
    "    \n",
    "    #create 95% confidence interval for population mean weight\n",
    "    ic = st.t.interval(alpha=0.95, df=len(data)-1, loc=np.mean(data), scale=st.sem(data))\n",
    "    \n",
    "    return tuple(round(valor, 3) for valor in ic) # arredonda pra 3 casas decimais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean rank: 1.771(1.349, 2.193), Acc: 0.92, MRR: 0.95(0.935, 0.958) with dbsearch size: 20000\n",
      "Mean rank: 2.414(1.68, 3.148), Acc: 0.9, MRR: 0.93(0.915, 0.942) with dbsearch size: 40000\n",
      "Mean rank: 3.078(2.027, 4.129), Acc: 0.88, MRR: 0.91(0.9, 0.93) with dbsearch size: 60000\n",
      "Mean rank: 3.92(2.451, 5.389), Acc: 0.87, MRR: 0.9(0.889, 0.921) with dbsearch size: 80000\n",
      "Mean rank: 4.634(2.8, 6.468), Acc: 0.86, MRR: 0.9(0.881, 0.914) with dbsearch size: 100000\n",
      "CPU times: user 24min 17s, sys: 38min 37s, total: 1h 2min 54s\n",
      "Wall time: 18min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# checkpoint-9000 (best_model)\n",
    "dbsizes = [20000, 40000, 60000, 80000, 100000]\n",
    "for dbsize in dbsizes:\n",
    "    ranks = []\n",
    "    search = dbsearch[:dbsize]\n",
    "    for i in range(len(query)):\n",
    "        ranks.append(rank(query[i], i, search)) # rank das ta' no dbsearch!\n",
    "    print('Mean rank: {}{}, Acc: {}, MRR: {}{} with dbsearch size: {}'.format(mr(ranks), cip_r(ranks), acc(ranks), mrr(ranks), cip_rr(ranks), dbsize))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOqaLWH44Jej+GzpQB7LCw5",
   "collapsed_sections": [
    "3CNDIKIh5PxT"
   ],
   "machine_shape": "hm",
   "mount_file_id": "180jxnrEfenoBKq14C11iOaIFCq1ZhZJv",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
