{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20778,
     "status": "ok",
     "timestamp": 1694647048649,
     "user": {
      "displayName": "Wilken Charles",
      "userId": "08238201343018523362"
     },
     "user_tz": 180
    },
    "id": "6jCyskjWe-Ii",
    "outputId": "01727a8a-89f3-4f49-f283-94540035a77c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.33.1-py3-none-any.whl (7.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
      "Collecting huggingface-hub<1.0,>=0.15.1 (from transformers)\n",
      "  Downloading huggingface_hub-0.17.1-py3-none-any.whl (294 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.8/294.8 kB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
      "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
      "  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m49.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
      "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
      "Successfully installed huggingface-hub-0.17.1 safetensors-0.3.3 tokenizers-0.13.3 transformers-4.33.1\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 14800,
     "status": "ok",
     "timestamp": 1694647063434,
     "user": {
      "displayName": "Wilken Charles",
      "userId": "08238201343018523362"
     },
     "user_tz": 180
    },
    "id": "VP6Iw6AxfEcq"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KDTree\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "\n",
    "from transformers import BertConfig, BertForMaskedLM, BertTokenizer, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 984,
     "status": "ok",
     "timestamp": 1694647064403,
     "user": {
      "displayName": "Wilken Charles",
      "userId": "08238201343018523362"
     },
     "user_tz": 180
    },
    "id": "Tndw-RF7cbbo",
    "outputId": "6a166462-bdbd-4f87-8288-dda5ca093a29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D_p-pts.pickle\texp1-trj.h5\texp1-trj.t   README.md\t   train.trg  vocab.txt\r\n",
      "D_q-pts.pickle\texp1-trj.label\texp2-trj.h5  saved_models  val.src\r\n",
      "Dq-pts.pickle\texp1-trj.pts\tporto.csv    train.src\t   val.trg\r\n"
     ]
    }
   ],
   "source": [
    "!ls '../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 978,
     "status": "ok",
     "timestamp": 1694647070290,
     "user": {
      "displayName": "Wilken Charles",
      "userId": "08238201343018523362"
     },
     "user_tz": 180
    },
    "id": "lmGMWgthaaMY",
    "outputId": "eb810229-dfc2-4b62-ef90-a0b8ea85dfd5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-wilken.dantas@ufc.-af1ea/.local/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:1730: FutureWarning: Calling BertTokenizer.from_pretrained() with the path to a single file or url is deprecated and won't be possible anymore in v5. Use a model identifier or the path to a directory instead.\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "# Load the tokenizer of t2vec\n",
    "vocab_file_dir = '../data/vocab.txt'\n",
    "tokenizer =  BertTokenizer.from_pretrained(vocab_file_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 312,
     "status": "ok",
     "timestamp": 1694647073974,
     "user": {
      "displayName": "Wilken Charles",
      "userId": "08238201343018523362"
     },
     "user_tz": 180
    },
    "id": "qMyv5C-wYxtt",
    "outputId": "a89091ab-85ef-421e-d46f-321d05ca9e4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_model  checkpoint-15000\r\n"
     ]
    }
   ],
   "source": [
    "!ls '../data/saved_models/BERT/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2596,
     "status": "ok",
     "timestamp": 1694647138971,
     "user": {
      "displayName": "Wilken Charles",
      "userId": "08238201343018523362"
     },
     "user_tz": 180
    },
    "id": "I76HDxeL3f4x",
    "outputId": "73e3d9b8-3357-432d-dbe1-6049a6a1ab0f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../data/saved_models/BERT/best_model/ were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertModel were not initialized from the model checkpoint at ../data/saved_models/BERT/best_model/ and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Carregando o modelo treinado:\n",
    "config = BertConfig.from_json_file('../data/saved_models/BERT/best_model/config.json')\n",
    "config.output_hidden_states=True\n",
    "model = BertModel.from_pretrained('../data/saved_models/BERT/best_model/', local_files_only=True, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding_mean_for_all_trajs(list_trajs):\n",
    "    tokenized_trajs = list_trajs\n",
    "    indexed_trajs_tokens = [tokenizer.convert_tokens_to_ids(traj) for traj in tokenized_trajs]\n",
    "\n",
    "    # Preenchendo as sequências para ter o mesmo comprimento (valor de preenchimento padrão = 0)\n",
    "    padded_inputs = rnn_utils.pad_sequence([torch.tensor(seq) for seq in indexed_trajs_tokens], batch_first=True)\n",
    "    #padded_inputs = padded_inputs.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(padded_inputs)\n",
    "\n",
    "    # Calcula a média dos embeddings de cada sentença (traj)\n",
    "    sentence_embeddings = torch.mean(outputs.last_hidden_state, dim=1)\n",
    "    return sentence_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectories = [['506', '112', '144', '148', '250', '258', '384'], ['148', '250', '258', '384']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5477, -0.2066,  0.2435,  ..., -0.4758, -0.9001,  0.2682],\n",
       "        [ 0.4124, -0.0651,  0.5063,  ..., -0.4328, -1.0516,  0.2307]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_embedding_mean_for_all_trajs(trajectories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "508 465 1641 857 3176 1346 1301 3303 3277 3977 4430 8513 9755 11383 9496 12228 11150 13279 9215 17279 14428 9279 14792 14310 18351 7997 15024 15267 15665 16329 15125 14591 14797 3\r\n",
      "19 191 68 41 46 4 964 543 154 171 382 732 632 923 4815 460 273 439 607 908 726 6277 5338 5821 6933 5438 8005 10438 9812 17030 12351 12132 13988 9320 5581 13142 15720 14944 5048 11012\r\n",
      "51 2263 345 53 120 405 803 585 692 1566 533 1728 1880 739 544 226 8\r\n",
      "15 4 58 9 38 54 196 648 193 1022 575 1560 753 229 260 532 317 764 159 633 1304 207 798 2811 301 211 880 80 23 89 40 537 781 141 5900 240 38 54 655 1616 196 648 437 749 575\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 4 '../data/exp1-trj.t'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 6573,
     "status": "ok",
     "timestamp": 1694647179149,
     "user": {
      "displayName": "Wilken Charles",
      "userId": "08238201343018523362"
     },
     "user_tz": 180
    },
    "id": "LodboHE6z2R0"
   },
   "outputs": [],
   "source": [
    "# Carregando as trajs de teste:\n",
    "trajs_teste = []\n",
    "with open('../data/exp1-trj.t') as f:\n",
    "    for line in f:\n",
    "        traj_list = line.strip().split()\n",
    "        trajs_teste.append(traj_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1694647179150,
     "user": {
      "displayName": "Wilken Charles",
      "userId": "08238201343018523362"
     },
     "user_tz": 180
    },
    "id": "bpT-8Hcxz2G2",
    "outputId": "49c66124-1053-4ef8-8473-e000178e14b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de trajetórias de teste: 101000\n"
     ]
    }
   ],
   "source": [
    "print(\"Quantidade de trajetórias de teste:\", len(trajs_teste))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['508', '465', '1641', '857', '3176', '1346', '1301', '3303', '3277', '3977', '4430', '8513', '9755', '11383', '9496', '12228', '11150', '13279', '9215', '17279', '14428', '9279', '14792', '14310', '18351', '7997', '15024', '15267', '15665', '16329', '15125', '14591', '14797', '3']\n"
     ]
    }
   ],
   "source": [
    "print(trajs_teste[0]) # --> primeira query (traj par)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1089', '465', '1123', '2173', '185', '307', '553', '4012', '3442', '4296', '4498', '7490', '7819', '7630', '9013', '11297', '11988', '10689', '18272', '12037', '11976', '15001', '15262', '15156', '14901', '7997', '13957', '16913', '16146', '15069', '15704', '16382', '16121', '16271', '3']\n"
     ]
    }
   ],
   "source": [
    "print(trajs_teste[1000]) # --> mais semelhante a primeira query, ou seja, traj ímpar!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 386,
     "status": "ok",
     "timestamp": 1694647188024,
     "user": {
      "displayName": "Wilken Charles",
      "userId": "08238201343018523362"
     },
     "user_tz": 180
    },
    "id": "fkv5lR35nvNq"
   },
   "outputs": [],
   "source": [
    "# Segmentando: query (trajs pares) e dbsearch (querys ímpar + 99000 outras ímpares)\n",
    "query = trajs_teste[:1000] # trajs query (pares)\n",
    "dbsearch = trajs_teste[1000:101000] # dbsearch trajs (as 1000 primeiras são as query ímpar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "100000\n"
     ]
    }
   ],
   "source": [
    "print(len(query))\n",
    "print(len(dbsearch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abaixo, pegamos os embeddings das trajs por lotes (10 em 10 trajs). Assim, evita-se estouro de memória..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 6s, sys: 483 ms, total: 6min 6s\n",
      "Wall time: 1min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "query_aux = torch.zeros(1000, 768)\n",
    "\n",
    "for i in range(0, len(query), 10):\n",
    "    query_aux[i:i+10] = get_embedding_mean_for_all_trajs(query[i:i+10]) # Pegando de 10 em 10\n",
    "    \n",
    "    # Calcula a porcentagem concluída\n",
    "    percent_done = ((i / len(query)) * 100)+1\n",
    "    print(f\"Progresso: {percent_done:.2f}% concluído\", end=\"\\r\")  # A opção `end=\"\\r\"` permite que a impressão seja substituída na mesma linha\n",
    "    \n",
    "query = query_aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8h 52min 48s, sys: 13.6 s, total: 8h 53min 1s\n",
      "Wall time: 2h 15min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dbsearch_aux = torch.zeros(100000, 768)\n",
    "\n",
    "for i in range(0, len(dbsearch), 10):\n",
    "    dbsearch_aux[i:i+10] = get_embedding_mean_for_all_trajs(dbsearch[i:i+10]) # Pegando de 10 em 10\n",
    "    \n",
    "    # Calcula a porcentagem concluída\n",
    "    percent_done = ((i / len(dbsearch)) * 100)+1\n",
    "    print(f\"Progresso: {percent_done:.2f}% concluído\", end=\"\\r\")  # A opção `end=\"\\r\"` permite que a impressão seja substituída na mesma linha\n",
    "    \n",
    "dbsearch = dbsearch_aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "print(type(query))\n",
    "print(type(dbsearch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertendo de Tensor pra Numpy\n",
    "query = query.numpy()\n",
    "dbsearch = dbsearch.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(query))\n",
    "print(type(dbsearch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5VPlYZOevrR4"
   },
   "source": [
    "## Time efficiency of BERT using KDTree "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5VPlYZOevrR4"
   },
   "source": [
    "### BertConfig():\n",
    "    hidden_size=768, (embedding size)\n",
    "    num_hidden_layers=6,\n",
    "    num_attention_heads=12,\n",
    "    max_position_embeddings=512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(q, db, k):\n",
    "    tree = KDTree(db)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    for i in range(len(q)):\n",
    "        _, ind = tree.query([q[i]], k=k)\n",
    "    end_time = time.time()\n",
    "    elapsed_time = round(end_time - start_time, 2)\n",
    "    print(f\"Knn time: {elapsed_time} segundos, with dbsize: {len(db)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Knn time: 18.77 segundos, with dbsize: 20000\n",
      "Knn time: 37.57 segundos, with dbsize: 40000\n",
      "Knn time: 59.62 segundos, with dbsize: 60000\n",
      "Knn time: 75.26 segundos, with dbsize: 80000\n",
      "Knn time: 104.32 segundos, with dbsize: 100000\n"
     ]
    }
   ],
   "source": [
    "dbsizes = [20000, 40000, 60000, 80000, 100000]\n",
    "for dbsize in dbsizes:\n",
    "    knn(query, dbsearch[:dbsize], 50)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNb7ADocPT+4khlxLjiFzWx",
   "collapsed_sections": [
    "3CNDIKIh5PxT"
   ],
   "machine_shape": "hm",
   "mount_file_id": "180jxnrEfenoBKq14C11iOaIFCq1ZhZJv",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
